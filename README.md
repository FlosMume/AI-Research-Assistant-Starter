# ai-research-assistant-starter

A minimal, productionâ€‘friendly starter for an **AI Research Assistant**. It wires together:

- **Speechâ€‘toâ€‘Text (ASR)** â€” Whisper / Fasterâ€‘Whisper (GPU if available)
- **Academic Retrieval** â€” arXiv search with snippet extraction
- **LLM Summarization** â€” ðŸ¤— Transformers pipeline (default: `facebook/bart-large-cnn`) with safe fallback
- **Textâ€‘toâ€‘Speech (TTS)** â€” `pyttsx3` (Windows speak) or Piper â†’ WAV on Linux/WSL
- **HTTP API** â€” FastAPI endpoints: `/ask`, `/status`, `/notion-sync`
- **Sessioning & Logging** â€” lightweight transcript and structured logs
- **Optional Notion sync** â€” stub to push transcripts

> Works great on **WSL + CUDA 12.x** (e.g., RTX 4070 SUPER) with Python 3.10 and Conda.  
> On WSL, TTS exports to a WAV file; on native Windows Python, `pyttsx3` can speak directly.

---

## Why this repo

- Clean, interviewâ€‘ready structure suitable for pinning on your GitHub profile
- Swappable components (ASR / Retriever / Summarizer / TTS)
- Small, readable codebase with a simple test to validate imports
- No proprietary assets or heavy data included

---

## Quickstart

```bash
# 0) Ensure NVIDIA driver & WSL GPU passâ€‘through (if using GPU)
nvidia-smi

# 1) Create environment (Python 3.10)
conda create -n research-assistant python=3.10 -y
conda activate research-assistant

# 2) System deps (Whisper needs FFmpeg)
sudo apt-get update && sudo apt-get install -y ffmpeg

# 3) Install Python deps
pip install -r requirements.txt

# 4) Run API
uvicorn app:app --reload --port 8000
```

**Try it**

- Text:
  ```bash
  curl -X POST http://localhost:8000/ask        -H "Content-Type: application/json"        -d '{"query":"Summarize recent advances in retrieval-augmented generation."}'
  ```

- Audio (WAV/MP3):
  ```bash
  curl -X POST "http://localhost:8000/ask" -F "audio_file=@input.wav"
  ```

Response includes: `answer`, `citations` (arXiv IDs), and `tts_wav` (path to WAV file if generated).

---

## Configuration

Edit `.env` (copy from `.env.example`) or set env vars:

- `ASR_BACKEND` = `faster_whisper` | `whisper` | `none`
- `USE_GPU` = `1` or `0`
- `SUMMARIZER_MODEL` = huggingface model id (default: `facebook/bart-large-cnn`)
- Optional Notion: `NOTION_API_KEY`, `NOTION_PAGE_ID`

---

## Project Layout

```
ai-research-assistant-starter/
â”œâ”€ app.py
â”œâ”€ config.py
â”œâ”€ state.py
â”œâ”€ tools/
â”‚  â”œâ”€ asr.py
â”‚  â”œâ”€ retriever.py
â”‚  â”œâ”€ llm.py
â”‚  â”œâ”€ tts.py
â”‚  â””â”€ notion_sync.py
â”œâ”€ tests/
â”‚  â””â”€ test_smoke.py
â”œâ”€ cli.py
â”œâ”€ requirements.txt
â”œâ”€ environment.yml
â”œâ”€ .env.example
â”œâ”€ .gitignore
â””â”€ README.md
```

---

## Technical Verification (available upon request)

A compact **verification bundle** (script + fixtures) can be shared privately to validate:
- ASR is functional with a sample audio clip (Whisper / Fasterâ€‘Whisper)
- Retrieval returns deterministic arXiv results for a fixed query
- Summarizer produces a nonâ€‘empty answer within expected latency bounds
- TTS generates a playable WAV file (Linux/WSL) or speaks via `pyttsx3` (Windows)
- API contract: `/ask` responds with `answer`, `citations`, and `tts_wav`

> For reviewers: request the verification pack to reproduce results quickly without exposing private assets.

---

## Notes

- On **WSL**, audio playback is handled by exporting WAV; you can play with `ffplay` or copy to Windows.
- For speed, you may switch the summarizer to a smaller model (e.g., `sshleifer/distilbart-cnn-12-6`).
- Retrieval is abstracted; swap arXiv with your own corpus or a vector database later.

---

## License

MIT
